<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/wanjuya32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/wanjuya16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Gemini","version":"7.7.1","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="最近阅读了Interpretable Machine Learning这本书，将书中内容简单进行了总结，分为上中下三部分笔记，分别是1）可解释的模型 2）模型无关方法的解释 3）基于样本的解释">
<meta property="og:type" content="article">
<meta property="og:title" content="可解释的机器学习(中)">
<meta property="og:url" content="http://yoursite.com/2020/05/26/%E5%8F%AF%E8%A7%A3%E9%87%8A%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0(%E4%B8%AD)/index.html">
<meta property="og:site_name" content="窝">
<meta property="og:description" content="最近阅读了Interpretable Machine Learning这本书，将书中内容简单进行了总结，分为上中下三部分笔记，分别是1）可解释的模型 2）模型无关方法的解释 3）基于样本的解释">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/image/Interpre7.png">
<meta property="og:image" content="http://yoursite.com/image/Intepre8.png">
<meta property="og:image" content="http://yoursite.com/image/Intepre9.png">
<meta property="og:image" content="http://yoursite.com/image/Intepre10.png">
<meta property="og:image" content="http://yoursite.com/image/Intepre11.png">
<meta property="og:image" content="http://yoursite.com/image/Intepre12.png">
<meta property="og:image" content="http://yoursite.com/image/Intepre13.png">
<meta property="og:image" content="http://yoursite.com/image/Intepre14.png">
<meta property="og:image" content="http://yoursite.com/image/Intepre15.png">
<meta property="og:image" content="http://yoursite.com/image/Intepre16.png">
<meta property="og:image" content="http://yoursite.com/image/Intepre17.png">
<meta property="og:image" content="http://yoursite.com/image/Intepre20.png">
<meta property="og:image" content="http://yoursite.com/image/Intepre18.png">
<meta property="og:image" content="http://yoursite.com/image/Intepre19.png">
<meta property="article:published_time" content="2020-05-26T08:37:04.130Z">
<meta property="article:modified_time" content="2020-05-27T12:09:18.883Z">
<meta property="article:author" content="杨继琛">
<meta property="article:tag" content="Interpretable">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/image/Interpre7.png">

<link rel="canonical" href="http://yoursite.com/2020/05/26/%E5%8F%AF%E8%A7%A3%E9%87%8A%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0(%E4%B8%AD)/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>可解释的机器学习(中) | 窝</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>
    <a href="https://github.com/yangjichen" target="_blank" rel="noopener" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; left: 0; transform: scale(-1, 1);" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style></a>

    
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">窝</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">菜鸡阿琛個人小站</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">16</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类<span class="badge">10</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">26</span></a>

  </li>
  </ul>

</nav>
</div>
    </header>

    


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/26/%E5%8F%AF%E8%A7%A3%E9%87%8A%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0(%E4%B8%AD)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/1.jpg">
      <meta itemprop="name" content="杨继琛">
      <meta itemprop="description" content="jichenyeung@gmail.com">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="窝">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          可解释的机器学习(中)
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-05-26 16:37:04" itemprop="dateCreated datePublished" datetime="2020-05-26T16:37:04+08:00">2020-05-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-05-27 20:09:18" itemprop="dateModified" datetime="2020-05-27T20:09:18+08:00">2020-05-27</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>最近阅读了Interpretable Machine Learning这本书，将书中内容简单进行了总结，分为上中下三部分笔记，分别是1）可解释的模型 2）模型无关方法的解释 3）基于样本的解释</p>
 <a id="more"></a>
<h1 id="第五章-模型无关的方法"><a href="#第五章-模型无关的方法" class="headerlink" title="第五章 模型无关的方法"></a>第五章 模型无关的方法</h1><p>个人总结：本章讲述了一下几个工具，我将其可使用性进行了评价。</p>
<ol>
<li>PDP可以看到某一变量取值对于最终预测的边际贡献值，缺点是不适用于变量有相关性的情况。</li>
<li>ICE与PDP反映内容相同，但是展示的是每个样本的某一变量对于最终预测的贡献，缺点同上</li>
<li>ALE 是部分依赖图 (PDP) 的更快、更无偏的替代方法。且当特征不独立的时候，ALE比PDP好用。<font color= 'red'>推荐去实现</font></li>
<li>特征交互分析中的H统计量，用来看预测时每个变量与剩余所有变量交互强度的大小，<font color= 'red'>我暂时没想到这有什么样的作用。</font></li>
<li>置换特征重要性。一种广义计算特征重要性的方法，不依赖于模型。<font color= 'red'>推荐去实现</font></li>
<li>全局代理模型：用可解释性强的简单模型去近似复杂模型。我认为没啥用！</li>
<li>局部代理模型：用来解释个体预测值是受什么样的局部决策边界影响。我认为有点像是基于样本的解释。<font color= 'blue'>我觉得用处不大，但是书中比较多的出现</font></li>
<li>Shapley值：给定当前的一组属性值，属性值对实际预测值与平均预测值之差的贡献就是估计的 Shapley 值。我认为这个可以用来解释某一个体为什么预测值比均值要低多少。<font color= 'blue'>推荐去实现有相同功能但是更加快和广泛的SHAP值</font></li>
<li>SHAP值：基于博弈论上的最佳 Shapley 值，我认为这个是实现个体预测解释很好的工具！另外这也可以作为重要性度量去实现。<font color= 'red'>推荐去实现</font></li>
</ol>
<p>综上：去做model free解释性的时候，ALE、置换特征重要性、SHAP是三个我认为最值得去实现的工具。</p>
<hr>
<h2 id="介绍："><a href="#介绍：" class="headerlink" title="介绍："></a>介绍：</h2><p>1）与模型无关 (也称模型不可知) 的解释方法的最大优势是它们的<strong>灵活性（独立于模型）</strong>。当解释方法可以应用于任何模型时，机器学习开发人员可以自由使用他们喜欢的任何机器学习模型。2）从可解释性来比较多个模型的时候，使用与模型无关的解释会更容易，因为相同的方法 可以用于任何类型的模型。</p>
<p>下图是个非常好的解释，将模型和解释分为两个层，先有模型之后，我们再来看其<strong>可解释性方法层</strong></p>
<p><img src="/image/Interpre7.png" alt="image-20200526162212453" style="zoom:30%;" /></p>
<h2 id="5-1-部分依赖图（Partial-Dependence-Plot）"><a href="#5-1-部分依赖图（Partial-Dependence-Plot）" class="headerlink" title="5.1 部分依赖图（Partial Dependence Plot）"></a>5.1 部分依赖图（Partial Dependence Plot）</h2><font color='red'>PDP显示了**一个或两个特征**对机器学习模型的预测结果的边际效应</font>，（预测结果对于一两个特征的部分依赖关系）

**1. 考虑连续特征，**在回归中,
$$
\hat{f}_{x_{S}}\left(x_{S}\right)=E_{x_{C}}\left[\hat{f}\left(x_{S}, x_{C}\right)\right]=\int \hat{f}\left(x_{S}, x_{C}\right) d \mathbb{P}\left(x_{C}\right)
$$
部分依赖函数告诉我们特征 S 的给定值对预测的平均边际效应是多少，求解时候可以通过MC方法，（**重点：因为上面求积分是dP(x_c)，所以尽量都使用原始样本里面C属性的分布**）
$$
\hat{f}_{x_{S}}\left(x_{S}\right)=\frac{1}{n} \sum_{i=1}^{n} \hat{f}\left(x_{S}, x_{C}^{(i)}\right)
$$
PDP的**重要假设**是C 中的特征与 S 中的特征不相关。

**2. 考虑分类特征**，部分依赖很容易计算，为了计算 “夏季” 的值，我们将所有数据实例的季节替换为 “夏季”，然后对预测取平均值。

书上的例子是各类特征对于自行车租赁的影响，连续变量的话得到一个曲线，离散的话得到不同取值下的预测值

<img src="/image/Intepre8.png" alt="image-20200526181244765" style="zoom:30%;" />

* 优点：部分依赖图的计算很直观:如果我们强制所有数据点都假定该特征值，则特定特征值处的部分依赖

    函数表示平均预测。

* 缺点：1）最大特征数量为2，因为人脑想象不来更高维；**2）**PD 图未显示特征分布。忽略分布可能会产生误导，因为你可能会过度解释几乎没有数据的区域。所以通过再画一个分布直方图是一个比较好的辅助措施。3）独立性假设是最大的问题，解决方案是使用适用于条件分布的累积局部效应图或简称 ALE 图。4）**异质效应**可能被隐藏，因为 PD 曲线仅显示平均边际效应。假设只有两个点i和j，假设对于一个特征s，$c_i$的作用下s越大，预测值越大——$c_j$作用下s越小，预测值越大。PD 曲线可能是一条水平线，因为数据集这两个点的效果可能会相互抵消。然后，**错误得出结论该特征对于预测没有影响**

<font color='red'>这里需要再理解下什么是异质性</font>

<h2 id="5-2-个体条件期望-Individual-Conditional-Expectation）"><a href="#5-2-个体条件期望-Individual-Conditional-Expectation）" class="headerlink" title="5.2 个体条件期望 (Individual Conditional Expectation）"></a>5.2 个体条件期望 (Individual Conditional Expectation）</h2><p>为了解决上面PDP的缺点4，我们使用ICE。为每个样本画一条预测线(C属性不变，S属性从小到大)，共得到n条线。上述的PDP其实是ICE上所有线的平均值。<strong>如果ICE上所有曲线都遵循相同的路线，那说明没有明显的相互作用，没有异质效应。这意味着 PDP 已经很好地概括了S特征对机器学习模型的预测结果的边际效应。</strong></p>
<p><img src="/image/Intepre9.png" alt="image-20200526181222574" style="zoom:30%;" /></p>
<ol>
<li><p>ICE 图存在一个问题:有时很难判断 ICE 图在个体之间是否不同，因为它们从不同的预测开始。一种简单的解决方案是将曲线中心化于特征中的某个点，并仅显示到该点的预测差异。结果图称为中心化 ICE 图 (c-ICE)$\hat{f}<em>{c e n t}^{(i)}=\hat{f}^{(i)}-\mathbf{1} \hat{f}\left(x^{a}, x</em>{C}^{(i)}\right)$。中心化 ICE 图使比较单个实例的曲线变得更加容易。如果我们不希望看到预测值的绝对变化，而 是希望预测与特征范围的固定点相比的差异，这将很有用。</p>
</li>
<li><p>导数 ICE 图 (d-ICE)从视觉上更容易发现异质性：观察预测函数相对于特征的导数。但d-ICE 图需要很长时间才能计算出来， 这是不切实际的。</p>
</li>
</ol>
<script type="math/tex; mode=display">
\hat{f}(x)=\hat{f}\left(x_{S}, x_{C}\right)=g\left(x_{S}\right)+h\left(x_{C}\right), \quad \text { with } \quad \frac{\delta \hat{f}(x)}{\delta x_{S}}=g^{\prime}\left(x_{S}\right)</script><ul>
<li><p>优点：一个曲线代表一个点的预测，更加直观；相比PDP来说更能揭示异质关系。</p>
</li>
<li><p>缺点：1）只能画一个特征，两个特征已经重叠到看不清。2）拥挤，可视化效果差。3）与 PDP 面临相同的问题:如果感兴趣的特征与其他特征相关联，则根据联合特征分布， 线中的某些点可能是无效的数据点。</p>
</li>
</ul>
<h2 id="5-3-累积局部效应-Accumulated-Local-Effects-Plot"><a href="#5-3-累积局部效应-Accumulated-Local-Effects-Plot" class="headerlink" title="5.3 累积局部效应(Accumulated Local Effects Plot)"></a>5.3 累积局部效应(Accumulated Local Effects Plot)</h2><font color = 'red'>能反映出和PDP相同想法的图，某个变量变化时会对预测值产生什么样的影响，但更加好用，如果之后需要用的话建议再深入看看理论。实习或许用得到</font>    

<p>描述了特征平均如何影响机器学习模型的预测。ALE 图是部分依赖图 (PDP) 的更快、更无偏的替代方法。且当特征不独立的时候，ALE比PDP好用。</p>
<p>比如x1 x2完全正相关，那么就不可能出现x1 = 0.7,x2=0.3的属性变量，计算条件分布时会过滤这种情况</p>
<p>如果机器学习模型的特征相关，则部分依赖图将不可信。计算与其他特征强相关的特征的部分依赖 图涉及对在实际中不太可能出现的人工数据实例的平均预测。这会极大地影响估计的特征效应。</p>
<p><img src="/image/Intepre10.png" alt="image-20200526203602262" style="zoom:40%;" /></p>
<h4 id="理论："><a href="#理论：" class="headerlink" title="理论："></a>理论：</h4><p>PD，M 和 ALE 图在数学上有何不同?这三种方法的共同点是将复杂的预测函数 f 简化为仅依赖 一个 (或两个) 特征的函数。这三种方法都通过平均其他特征的效应来简化特征，但是在计算预测平均值或预测差异以及是否对边际或条件分布进行平均方面有所不同。</p>
<ol>
<li>PD对对边际分布的预测进行平均。<strong>要计算边际分布上的期望值，我们只需获取所有数据实例，强制它们对集合 S 中的特征具有特定的网格值，C属性按照各自原来的，平均此操作下数据集的预测值。</strong></li>
</ol>
<script type="math/tex; mode=display">
\begin{aligned}PD =  \hat{f}_{x_{S}, P D P}\left(x_{S}\right) &=E_{X_{C}}\left[\hat{f}\left(x_{S}, X_{C}\right)\right] \\ &=\int_{x_{C}} \hat{f}\left(x_{S}, x_{C}\right) \mathbb{P}\left(x_{C}\right) d x_{C} \end{aligned}</script><ol>
<li>M 图对<strong>条件分布</strong>的预测平均。</li>
</ol>
<script type="math/tex; mode=display">
\begin{aligned} \hat{f}_{x_{S}, M}\left(x_{S}\right) &=E_{X_{C} | X_{S}}\left[\hat{f}\left(X_{S}, X_{C}\right) | X_{S}=x_{s}\right] \\ &=\int_{x_{C}} \hat{f}\left(x_{S}, x_{C}\right) \mathbb{P}\left(x_{C} | x_{S}\right) d x_{C} \end{aligned}</script><ol>
<li>ALE 图对预测的变化进行平均，然后将其累积在网格上</li>
</ol>
<script type="math/tex; mode=display">
\begin{aligned} \hat{f}_{x_{S}, A L E}\left(x_{S}\right) &=\int_{z_{0,1}}^{x_{S}} E_{X_{C} | X_{S}}\left[\hat{f}^{S}\left(X_{s}, X_{c}\right) | X_{S}=z_{S}\right] d z_{S}-\text { constant } \\ &=\int_{z_{0,1}}^{x_{S}} \int_{x_{C}} \hat{f}^{S}\left(z_{s}, x_{c}\right) \mathbb{P}\left(x_{C} | z_{S}\right) d x_{C} d z_{S}-\text { constant } \end{aligned}</script><p>2与3的差异：1）$\hat{f}^{S}\left(x<em>{s}, x</em>{c}\right)=\frac{\delta \hat{f}\left(x<em>{S}, x</em>{C}\right)}{\delta x_{S}}$这一项其实是S区间中平均预测的变化，即梯度。2）比较来看ALE其实是M的积分形式。3）减去cons做中心化</p>
<p>问题：并不是所有模型都有梯度，比如随机森林</p>
<h4 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h4><p>为了估计局部效应，我们将特征划分为许多区间并计算预测值之间的差异。此过程近似梯度，也适用于没有梯度的模型。先计算非中心化效应，</p>
<script type="math/tex; mode=display">
\hat{\tilde{f}}_{j, A L E}(x)=\sum_{k=1}^{k_{j}(x)} \frac{1}{n_{j}(k)} \sum_{i: x_{j}^{(i)} \in N_{j}(k)}\left[f\left(z_{k, j}, x_{\backslash j}^{(i)}\right)-f\left(z_{k-1, j}, x_{\backslash j}^{(i)}\right)\right]</script><p>再将效应中心化，因此平均效应为零，</p>
<script type="math/tex; mode=display">
\hat{f}_{j, A L E}(x)=\hat{\tilde{f}}_{j, A L E}(x)-\frac{1}{n} \sum_{i=1}^{n} \hat{\tilde{f}}_{j, A L E}\left(x_{j}^{(i)}\right)</script><p>对于二维数值特征，做 2D ALE 图，计算就从间隔变成了矩阵间隔</p>
<h4 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h4><p><img src="/image/Intepre11.png" alt="image-20200526205730056" style="zoom:40%;" /></p>
<p>优点：1）ALE 图是无偏的，这意味着在特征相关时它们仍然有效。在这种情况下，部分依赖图将失败，因为它们会计算不可能的特征值组合。2）ALE 绘图的计算速度比 PDP 更快。3）ALE 图的解释很清楚:在给定值的条件下，可以从 ALE 图中读取更改特征对预测的相对影响（相对是指ALE 图以 0 为中心。这使它们的解释更好，因为 ALE 曲线每个点的值都是与平均预测之差）。</p>
<font color = 'red'>总而言之，在大多数情况下，宁愿使用 ALE 图而不是 PDP 图，因为特征通常在某种程度上相关。</font>

<p>缺点：1）间隔数过大时图形不稳定。2）实现更加复杂且不直观。<strong>3）目前仅在R语言中有实现</strong></p>
<h2 id="5-4-特征交互的分析（暂时没想到有什么实际用处）"><a href="#5-4-特征交互的分析（暂时没想到有什么实际用处）" class="headerlink" title="5.4 特征交互的分析（暂时没想到有什么实际用处）"></a>5.4 特征交互的分析（暂时没想到有什么实际用处）</h2><p>特征交互 (Feature Interaction) :当特征在预测模型中交互时，预测不能表示为特征效应的总和，因为一个特征的效应取决于另一特征的值。如果机器学习模型基于两个特征进行预测，则可以将预测分解为四项:常量项，第一个特征项，第二个特征项以及两个特征间的交互项。</p>
<ul>
<li>估计交互强度的一种方法是衡量预测的变化在多大程度上取决于特征的交互作用。这项衡量称为 H 统计量，</li>
</ul>
<ol>
<li>特征j和k之间的H统计量为：</li>
</ol>
<script type="math/tex; mode=display">
H_{j k}^{2}=\sum_{i=1}^{n}\left[P D_{j k}\left(x_{j}^{(i)}, x_{k}^{(i)}\right)-P D_{j}\left(x_{j}^{(i)}\right)-P D_{k}\left(x_{k}^{(i)}\right)\right]^{2} / \sum_{i=1}^{n} P D_{j k}^{2}\left(x_{j}^{(i)}, x_{k}^{(i)}\right)</script><ol>
<li>度量特征 j 是否与任何其他特征交互:</li>
</ol>
<script type="math/tex; mode=display">
H_{j}^{2}=\sum_{i=1}^{n}\left[\hat{f}\left(x^{(i)}\right)-P D_{j}\left(x_{j}^{(i)}\right)-P D_{-j}\left(x_{-j}^{(i)}\right)\right]^{2} / \sum_{i=1}^{n} \hat{f}^{2}\left(x^{(i)}\right)</script><p><strong>特点：</strong>H 统计量的评估成本很高，因为它会在所有数据点上进行迭代，并且必须在每个点处评估部分依 赖，而这又需要对所有 n 个数据点进行。在最坏的情况下，我们需要 $2n^2$ 调用机器学习模型预测 函数来计算双向 H 统计量 (j vs. k)，并需要 $3n^2$ 以获得总体 H 统计量 (j vs. all)。</p>
<h4 id="例子-1"><a href="#例子-1" class="headerlink" title="例子"></a>例子</h4><p>一般先查看每个特征与所有其他特征的特征交互量，然后可以选择其中一个H值大的特征，更深入地研究所选特征与其他特征之间的所有双向交互。</p>
<p><img src="/image/Intepre12.png" alt="image-20200526212334996" style="zoom:30%;" /></p>
<p><img src="/image/Intepre13.png" alt="image-20200526212348936" style="zoom:30%;" /></p>
<p>优点：理论基础、有意义的解释（H定义为由交互作用解释的方差份额）、0到1之间在不同模型间有可比性</p>
<p>缺点：计算量很大、H多大时称为“强”</p>
<h2 id="5-5-置换特征重要性（用于计算变量的重要性，model-free，实习可以尝试用，比起之前模型限定的重要性度量，这个好用太多。可以神经网络、RF）"><a href="#5-5-置换特征重要性（用于计算变量的重要性，model-free，实习可以尝试用，比起之前模型限定的重要性度量，这个好用太多。可以神经网络、RF）" class="headerlink" title="5.5 置换特征重要性（用于计算变量的重要性，model free，实习可以尝试用，比起之前模型限定的重要性度量，这个好用太多。可以神经网络、RF）"></a>5.5 置换特征重要性（用于计算变量的重要性，model free，实习可以尝试用，比起之前模型限定的重要性度量，这个好用太多。可以神经网络、RF）</h2><p>我们通过置换特征后计算模型的预测误差的增加来<strong>衡量特征的重要性</strong>。如果将 特征的值改变会增加模型误差，则该特征 “重要”，因为在这种情况下，模型依赖于特征进行预测。 如果将特征的值改变而使模型误差保持不变，则特征 “不重要”，因为在这种情况下，模型会忽略 预测的特征。</p>
<font color ='red'>一种广义计算特征重要性的方法，不依赖于模型</font> Fisher、Rudin 和 Dominici (2018)[31] 提出了特征重要性的模型无关版本，并将其称为模型依赖 (Model Reliance)

未详细看定义与idea，需要的时候再看，下面是一个例子。

<img src="/image/Intepre14.png" alt="image-20200526213830867" style="zoom:40%;" />

优点：1）很好的解释:特征重要性是当特征信息被破坏时模型误差的增加。2）提供了对模型行为的高度压缩的、全局的洞悉。3）不需要重新训练模型（其他一些方法建议删除特征，重新训练模型，然后比较模型误差，比起这个方法时间很久）

缺点：1）非常不清楚应该使用训练数据还是测试数据来计算特征的重要性。2）重复置换后，结果可能会有很大差异。3）如果特征是相关的，则置换特征重要性可能会因不切实际的数据实例而有偏差。





## 5.6 全局代理模型（我认为这个工作比较无聊，例子：决策树去近似复杂模型的预测）

理论：我们希望在 g 可解释的约束下，代理模型 预测函数 g 尽可能接近地逼近我们的黑盒预测函数 f。对于函数 g，可以使用任何可解释的模型。训练代理模型是一种与模型无关的方法，因为它不需要有关黑盒模型内部运作的任何信息，仅需要 访问数据和预测。

训练流程：1）对于选定的数据集 X，获取黑盒模型的预测。2）选择一种可解释的模型类型 (线性模型，决策树等)。3）在数据集 X 及其预测上训练可解释模型。4）衡量代理模型复制黑盒模型预测的效果（可使用R-square来看可解释模型可否替换复杂模型）。 5）解释代理模型。

优点：灵活、直观、R平方度量表现

缺点：得到的是有关模型而不是数据的结论，选择的可解释的代理模型本身的所有优点和缺点。





## 5.7 局部代理模型（Local interpretable model-agnostic explanations，LIME。用来解释个体预测值是受什么样的局部决策边界影响。我认为有点像是基于样本的解释）

局部代理模型本身是可解释的模型，用于解释黑盒机器学习模型的单个实例预测。LIME 并非训练全局代理模型，而是专注于训练局部代理模型以解释单个预测。

LIME 生成一个新的数据集， 该数据集由扰动的样本和黑盒模型的相应预测组成。然后，在这个新的数据集上，LIME 训练了一 个可解释的模型。在数学上，具有可解释性约束的局部代理模型可以表示为:
$$
\operatorname{explanation}(x)=\arg \min _{g \in G} L\left(f, g, \pi_{x}\right)+\Omega(g)
$$

**训练局部代理模型的方法：**1） 选择你想要对其黑盒预测进行解释的感兴趣实例。2） 扰动你的数据集并获得这些新点的黑盒预测。3） 根据新样本与目标实例的接近程度对其进行加权。 4）在新数据集上训练加权的，可解释的模型。5）通过解释局部模型来解释预测。

下图就是训练及解释的过程，先训练，然后得到局部的决策边界来解释

<img src="/image/Intepre15.png" alt="image-20200527161945519" style="zoom:40%;" />

优点：1）解释与模型分离2）少数适用于表格数据，文本和图像的方法之一。3）python LIME package有实现

缺点：以 LIME 作为具体实现的局部代理模型非常有应用前景。但是该方法仍处于开发阶段，需要解决许多问题才能安全应用。





## 5.8 Shapley值（给定当前的一组属性值，属性值对实际预测值与平均预测值之差的贡献就是估计的 Shapley 值。我认为这个可以用来解释某一个体为什么预测值比均值要低多少。非常好的工具，它的拓展是下一节的SHAP，理解shapley后最好使用SHAP）

例子：公寓的大小为 50 平方米，位于 2 楼，附近有公园，并且禁止猫入内，预测价格300,000，所有公寓的平均预测价格为 310,000 欧元。想知道与平均预测相比，减少的这10,000中每个属性值对预测有多少贡献?

思路：Shapley 值 (由 Shapley (1953)[33] 创造) 是一种根据 玩家对总支出的贡献分配支出给玩家的方法。**Shapley 值是所有可能的联盟 (Coalition) 中特征值的平均边际贡献。这么说清楚了吗?**<font color = 'red'>（个人理解，如果特定于“禁止猫进入”这一属性的Shapley值而言，这里可能的联盟是指将其他属性进行组合）</font>

<p><img src="/image/Intepre16.png" alt="image-20200527164921244" style="zoom:40%;" /></p>
<h4 id="示例与解释："><a href="#示例与解释：" class="headerlink" title="示例与解释："></a>示例与解释：</h4><p>特征值 j 的 Shapley 值的解释是:与数据集的平均预测相比，第 j 个特征的值对这个特定实例的预测的贡献为 φj。</p>
<p>Shapley适合解释分类（预测是概率）与回归问题。如下面的例子，1）每个特征对与<strong>女性患癌的概率比平均预测 值 0.03 高 0.54</strong>做了多大贡献。2）自行车例子</p>
<p><img src="/image/Intepre17.png" alt="image-20200527165605467" style="zoom:40%;" /></p>
<p><img src="/image/Intepre20.png" alt="image-20200527165617730" style="zoom:40%;" /></p>
<font color = 'red'>直觉 理解 Shapley 值的一种直观方法:属性值以随机顺序进入房间。房间中的所有属性值都参与游戏 (= 有助于预测)。属性值j的 Shapley 值是当该特征值加入它们时，已经存在于房间中的联盟所受到的预测的平均变化。</font>

<p><strong>计算</strong>：精确计算复杂度极大，所以大多使用蒙特卡洛近似</p>
<p><strong>特点</strong>：Shapley 值是唯一满足效益性 (Efficiency)，对称性 (Symmetry)，虚拟性 (Dummy) 和可加性 (Additivity) 的归因方法，这些性质一起可以视为公平支出的定义。</p>
<p><strong>优点</strong>：1）预测值与平均预测值之间的差异在实例的属性值 (即各属性的 Shapley 值) 之间公平分配。2）Shapley 值允许进行对比性解释。你可以将其与子集甚至单个数据点进行比较。这种对比也是像 LIME 这样的局部模型所不具备的。 3）Shapley 值是唯一具有扎实理论的解释方法。<strong>公理——效益性，对称性，虚拟性，可加性</strong>——为解 释提供了合理的基础。</p>
<p><strong>缺点</strong>：1）由于计算复杂，大多数情况只能近似计算。2）可能会被误解。特征值的 Shapley 值不是从模型训练中删除特征后的预测值之差。精确解释是:给定当前的一组特征值，特征值对实际预测值与平均预测值之差的贡献就是估计的 Shapley 值。3）计算时可能会遇到不现实的数据实例。4）目前只在R语言中有看到</p>
<h2 id="5-9-SHAP（基于博弈论上的最佳-Shapley-值，我认为这个是实现个体预测解释很好的工具！另外这也可以作为重要性度量）"><a href="#5-9-SHAP（基于博弈论上的最佳-Shapley-值，我认为这个是实现个体预测解释很好的工具！另外这也可以作为重要性度量）" class="headerlink" title="5.9 SHAP（基于博弈论上的最佳 Shapley 值，我认为这个是实现个体预测解释很好的工具！另外这也可以作为重要性度量）"></a>5.9 SHAP（基于博弈论上的最佳 Shapley 值，我认为这个是实现个体预测解释很好的工具！另外这也可以作为重要性度量）</h2><p>SHAP 的目标是通过计算每个特征对预测 x 的贡献来解释实例 x 的预测。SHAP 解释方法根据联盟博弈理论计算 Shapley 值。</p>
<p>Shapley 值是唯一满足效益性、对称性、虚拟性和可加性的解。SHAP 也满足这些要求，因为它可 以计算 Shapley 值。</p>
<p>特点：1）局部准确性。2）缺失性。3）一致性</p>
<p>模型：1）kernel SHAP 2）Tree SHAP（速度更快）</p>
<p><img src="/image/Intepre18.png" alt="image-20200527171406643" style="zoom:40%;" /></p>
<h4 id="SHAP-特征重要性"><a href="#SHAP-特征重要性" class="headerlink" title="SHAP 特征重要性"></a>SHAP 特征重要性</h4><p>SHAP 特征重要性背后的想法很简单:具有较大的 Shapley 绝对值的特征很重要。由于我们需要全 局重要性，因此我们在数据中对每个特征的 Shapley 绝对值取平均值:</p>
<script type="math/tex; mode=display">
I_{j}=\sum_{i=1}^{n}\left|\phi_{j}^{(i)}\right|</script><p>接下来，我们通过重要性对特征进行降序排序并绘制它们。下图显示了 SHAP 特征对于预测宫颈癌的经过训练的随机森林的 SHAP 特征重要性。</p>
<p><img src="/image/Intepre19.png" alt="image-20200527171556662" style="zoom:40%;" /></p>
<p>SHAP 特征重要性是置换特征重要性的替代方法。两种重要性度量之间存在很大差异:置换特征重 要性基于模型性能的下降。SHAP 基于特征归因的大小。</p>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ol>
<li><p>由于 SHAP 计算 Shapley 值，因此应用了 Shapley 值的所有优点:SHAP 在博弈论中具有扎实的理论基础。预测结果在特征值中公平分配。我们得到对比性解释，将预测与平均预测进行比较。</p>
</li>
<li><p>SHAP 连接 LIME 和 Shapley 值。这对于更好地了解这两种方法非常有用。它还有助于统一可</p>
<p> 解释机器学习的领域。</p>
</li>
<li><p>SHAP 可以快速实现基于树的模型。我认为这是 SHAP 普及的关键，因为采用 Shapley 值的最大 障碍是计算速度慢。</p>
</li>
</ol>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ol>
<li>Shapley 值的缺点</li>
<li>KernelSHAP 很慢，一般用tree-shap</li>
</ol>
<h4 id="软件"><a href="#软件" class="headerlink" title="软件"></a>软件</h4><p>作者在 Python SHAP 包中实现了 SHAP。此实现适用于 Python 的 scikit-learn 机器学习库中的 基于树的模型。shap 包也用于本章中的示例。SHAP 已集成到树增强框架 XGBoost 和 LightGBM 中。</p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>杨继琛
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://yoursite.com/2020/05/26/%E5%8F%AF%E8%A7%A3%E9%87%8A%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0(%E4%B8%AD)/" title="可解释的机器学习(中)">http://yoursite.com/2020/05/26/可解释的机器学习(中)/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Interpretable/" rel="tag"># Interpretable</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/05/18/%E5%8F%AF%E8%A7%A3%E9%87%8A%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0(%E4%B8%8A)/" rel="prev" title="可解释的机器学习(上)">
      <i class="fa fa-chevron-left"></i> 可解释的机器学习(上)
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/07/13/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E5%AD%A6%E4%B9%A0%E5%8F%8A%E6%96%B0IDEA/" rel="next" title="贝叶斯网络结构学习及新IDEA">
      贝叶斯网络结构学习及新IDEA <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#第五章-模型无关的方法"><span class="nav-number">1.</span> <span class="nav-text">第五章 模型无关的方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#介绍："><span class="nav-number">1.1.</span> <span class="nav-text">介绍：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-部分依赖图（Partial-Dependence-Plot）"><span class="nav-number">1.2.</span> <span class="nav-text">5.1 部分依赖图（Partial Dependence Plot）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-个体条件期望-Individual-Conditional-Expectation）"><span class="nav-number">1.3.</span> <span class="nav-text">5.2 个体条件期望 (Individual Conditional Expectation）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-3-累积局部效应-Accumulated-Local-Effects-Plot"><span class="nav-number">1.4.</span> <span class="nav-text">5.3 累积局部效应(Accumulated Local Effects Plot)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#理论："><span class="nav-number">1.4.0.1.</span> <span class="nav-text">理论：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#计算"><span class="nav-number">1.4.0.2.</span> <span class="nav-text">计算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#例子"><span class="nav-number">1.4.0.3.</span> <span class="nav-text">例子</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-4-特征交互的分析（暂时没想到有什么实际用处）"><span class="nav-number">1.5.</span> <span class="nav-text">5.4 特征交互的分析（暂时没想到有什么实际用处）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#例子-1"><span class="nav-number">1.5.0.1.</span> <span class="nav-text">例子</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-5-置换特征重要性（用于计算变量的重要性，model-free，实习可以尝试用，比起之前模型限定的重要性度量，这个好用太多。可以神经网络、RF）"><span class="nav-number">1.6.</span> <span class="nav-text">5.5 置换特征重要性（用于计算变量的重要性，model free，实习可以尝试用，比起之前模型限定的重要性度量，这个好用太多。可以神经网络、RF）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#示例与解释："><span class="nav-number">1.6.0.1.</span> <span class="nav-text">示例与解释：</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-9-SHAP（基于博弈论上的最佳-Shapley-值，我认为这个是实现个体预测解释很好的工具！另外这也可以作为重要性度量）"><span class="nav-number">1.7.</span> <span class="nav-text">5.9 SHAP（基于博弈论上的最佳 Shapley 值，我认为这个是实现个体预测解释很好的工具！另外这也可以作为重要性度量）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#SHAP-特征重要性"><span class="nav-number">1.7.0.1.</span> <span class="nav-text">SHAP 特征重要性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#优点"><span class="nav-number">1.7.0.2.</span> <span class="nav-text">优点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#缺点"><span class="nav-number">1.7.0.3.</span> <span class="nav-text">缺点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#软件"><span class="nav-number">1.7.0.4.</span> <span class="nav-text">软件</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="杨继琛"
      src="/images/1.jpg">
  <p class="site-author-name" itemprop="name">杨继琛</p>
  <div class="site-description" itemprop="description">jichenyeung@gmail.com</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">26</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/yangjichen" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yangjichen" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:jichenyeung@gmail.com" title="E-Mail → mailto:jichenyeung@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

      
      <script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
      <script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
      <div class="widget-wrap">
          <h3 class="widget-title">Tag Cloud</h3>
          <div id="myCanvasContainer" class="widget tagcloud">
              <canvas width="250" height="250" id="resCanvas" style="width=100%">
            <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ADMM/" rel="tag">ADMM</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/A%E8%82%A1%E7%A0%94%E7%A9%B6/" rel="tag">A股研究</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bayesian-Network/" rel="tag">Bayesian Network</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Binary-Tensor/" rel="tag">Binary Tensor</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Count-Tensor/" rel="tag">Count Tensor</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Interpretable/" rel="tag">Interpretable</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Streaming/" rel="tag">Streaming</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tensor/" rel="tag">Tensor</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BF%A1%E8%B4%B7%E9%A3%8E%E6%8E%A7/" rel="tag">信贷风控</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C/" rel="tag">命令行</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B8%B8%E6%88%8F/" rel="tag">游戏</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%96%AB%E6%83%85/" rel="tag">疫情</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%88%86%E6%83%85%E5%88%86%E6%9E%90/" rel="tag">舆情分析</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%9D%A2%E8%AF%95/" rel="tag">面试</a><span class="tag-list-count">1</span></li></ul>
        </canvas>
        </div>
      </div>
    








    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">杨继琛</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.1
  </div>

        








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>

<script type="text/javascript" src="/js/src/clicklove.js"></script>
